<!DOCTYPE html>
<html>
<head>
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Inconsolata:wght@200..900&display=swap" rel="stylesheet">
<link rel="stylesheet" href="css.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@24,400,0,0" />
</head>
<body>

    <div id="intro">
      <h2>Hey, yo<a>u</a></h2>
      <h2>I'm Ale<a>x</a>,</h2>
      <h2>and I t<a>u</a>rn complex problems into</h2> 
      <h2>satisfy<a>i</a>ng design solutions.</h2>
    </div>
    
    <div id="scroller">
      <a href="#Projects">
        <span style="width: 100px;" class="material-symbols-outlined">arrow_downward</span>
      </a>
    </div>
    
    <div id="pagebreak"></div>
    
    <section id="Projects" class="Container">
      <div style="padding-top: 5%;"></div>
      <h3>What I've worked on</h3>
      <div class="ProjCard" onclick="openModal('P1')">Rethinking Delivery & Design Ops - Dyson</div>
      <div class="ProjCard" onclick="openModal('P2')">Digital Innovation - Dyson discovery team</div>
      <div class="ProjCard" onclick="openModal('P3')">Dyson OnTrac - MyDyson</div>
      <div class="ProjCard" onclick="openModal('P4')">Dyson Zone - Dyson Link</div>
      <div class="ProjCard" onclick="openModal('P5')">Digital upscaling - The Big Sleep Company</div>
      <div class="ProjCard" onclick="openModal('P6')">The Burning Reef - Digital Media (BSc) final project</div>
      <div class="ProjCard" onclick="openModal('P7')">Panacea experience - Prevail 2021</div>
      <div class="ProjCard" onclick="openModal('P8')">Critical Eye education tool - ICVL</div>
      <div class="ProjCard" onclick="openModal('P9')">SAM-APP for Anxiety - CodeWest</div>
      <!-- Add more ProjCards with unique modals -->
    </section>
    
    <div style="padding-top: 5%;"></div>
    
    <section id="Me" class="Container">
      <h3>Who I am</h3>
      <p>I'm a Senior Experience Designer at <a href="https://www.dyson.co.uk/">Dyson</a>. I've got 5 years of experience in design.</p>
      <p>I'm a relentless creative, easily inspired, and strive to find simplicity in the chaos.</p>
      <p>And recently I've found I love modern board games; I feel they represent an incredible culmination of so many design principles. Striving to keep components intuitive, tactile and minimal, while enabling a complex decision space all, and all while keeping the users core experience the goal of the product.</p>
      
      <div style="padding-top: 5%;"></div>

      <h3>Where to find me</h3>
      <p>If you've got an interesting opportunity or want to bounce ideas, find me on LinkedIn at <a>linkedin.com/in/ahop/</a>.</p>
    </section>

    <div style="padding-top: 5%;"></div>

    <!-- DesignOps -->
    <div id="P1" class="modal">
      <div class="modal-content">
        <span class="close" onclick="closeModal('P1')">&times;</span>
        <h1>Rethinking Delivery in Dyson - Design Ops</h1>
        <h3>Background</h3>
        <p>The Dyson Connectivity Experience Design team was facing growing inefficiencies in its design workflow due to the fast growth of the team that was not supported with effective design operations.
          This resulted in missed deadlines, inconsistent design quality, and poor collaboration - especially when globally collaborating across time zones where every moment counts.</p>
          <h3>Objective</h3>
          <p>To orchestrate the streamlining of our design process, and to optimise collaboration to amplify the design team's value and impact. This can be summed up in 3 key areas.</p>
          <img src="images/dyson_design_ops/framework.png" alt="How we work together, How we get work done, How our work creates impact">
          <h2 class="step1">Step 1: Audit current processes.</h2>
          <p><b>Research: </b>We conducted a comprehensive audit of the tools being used across the design and development teams. This involved surveying key stakeholders (designers, developers, product managers) to understand pain points. After running a workshop to collate feedback, the themes discovered were around.</p>
          <p><b>Fragmented Design Tools: </b>The design team had recently moved from Sketch to Figma, which led to inconsistency and skill gaps in the team. There were also areas designers were keen to upskill in such as animation and motion graphics.</p>
          <p><b>Onboarding new colleagues: </b>The design team tripled in size to over 50 to fit the expanding range of connected products across multiple international offices - but the lack of onboarding led to inconsistent processes.</p>
          <p><b>Inefficient Collaboration: </b>The handoff between designers and developers was time-consuming, leading to delays and miscommunications. Mostly in part due to an unclear definition of done for design work between innovation and delivery teams.</p>
          <p><b>Lack of Documentation: </b>The design team lacked proper documentation of design decisions, user research insights, and design guidelines, which led to misaligned and uninformed design choices.</p>
          <p><b>Collaboration Silos: </b>UX, product, and engineering teams were working in silos and critically not agile, which lead to misaligned goals, poor communication and duplication of work.</p>
          <p><b>Outcome: </b>This enabled us to get buy-in from the senior team and identify key areas of improvement and divide and conquer, the following steps are ones I’ve been directly involved in but there were other areas such as integrating the design system.</p>
          <h2 class="step2">Step 2: Rethinking our definition of done.</h2>
          <p><b>Solution: </b>Set up weekly design reviews that included not only designers but also product managers and developers. These reviews created a feedback loop early in the design process, reducing last-minute changes and identifying areas needed for a design to be considered ‘dev-ready’.</p>
          <p><b>Process: </b>Aligning the areas required for a design to be considered ‘dev-ready’ with other teams and building a Figma template with areas and guidance for every element that is required for delivery. As part of this we also covered the approval process for a piece of design work, you can see this below.</p>
          <img src="images/dyson_design_ops/signoff.png" alt="Flow chart of the approval process">
            <p><b>Outcome: </b>This improved collaboration and cross-team alignment, and highlighted other areas for attention such as accessibility documentation for voice over and colour blindness.</p>
          <h2 class="step3">Step 3: Standardising design documents; data tracking.</h2></p>
          <p><b>Solution: </b>While standardising design documentation, data tracking was a key area for improvement to help enable the data science team to align tracking requirements. You can see an example of how to present this below.</p>
          <img src="images/dyson_design_ops/datatracking.png" alt="Data tracking example">
          <p><b>Process: </b>Collaborating with the data science team on what parameters were necessary on a handover document for development, and creating an easily understood and adaptable figma component for all designers to easily import and use which makes it clear what type of tracking is required and what it tracks.</p>
          <p><b>Outcome: </b>Data tracking documentation on design files across teams has increased by ~80% with many overall awareness of data tracking increasing, and an improvement to the overall alignment of tracked data.</p>
          <h2 class="step4">Step 4: Animation and motion design workflow</h2>
          <p><b>Solution: </b>Document current workflow for animation, outlining the process, risks and business benefits.</p>
          <p><b>Process: </b>Onboarded multiple team members in each office location onto the animation process, to create a squad of animation advocates in the team. Then I presented to the wider team the benefits of animation, how to get started and how the current instance of animation for the Dyson Zone benefited the app experience.</p>
          <p>An overview of the presentation can be found below.</p>
          <img src="images/dyson_design_ops/animationdeck.png" alt="Business benefits of the Lottie with examples">
          <h3>Why use Lottie animation:</h3>
          <p>Animation is proven to drive engagement and retention while making the app appear more dynamic, interactive and responsive. It also enables assets to be scalable and lightweight.</p>
          <p>We should use Lottie animations in Dyson to build:</p>
          <ul>
            <li><b>Usability; </b>to improve feedback and user understanding. </li>
            <li><b>Delight; </b>build emotional connection with users.</li>
          </ul>
          <h3>Things to watch out for:</h3>
          <ul>
            <li>What are the goals of the animation, is it necessary?</li>
            <li>How will we measure the success of the animation?</li>
            <li>What is the benefit of spending time and resource animating?</li>
            <li>Has the animation concept been validated?</li>
            <li>Is the animation able to be delivered?</li>
          </ul>
          <h3>Process:</h3>
          <ul>
            <li>Storyboarding</li>
            <li>Asset generation / gathering</li>
            <li>Importing into After Effects</li>
            <li>Animation using keyframing.</li>
            <li>Enhancing with graph editor and animation principles.</li>
            <li>Exporting animation with BodyMovin plugin.</li>
            <li>Test and handover asset files to the development team.</li>
          </ul>
          <b>Outcome: </b>The amount of animations in the MyDyson app have increased from being present on only the Dyson Zone’s connected app experience, to being present on 4 different product app experiences across haircare and floorcare (+300%). The animation skillset is growing now with currently 7 designers spanning all offices now able to animate compared to the initial 2 designers based originally only in the UK (+250% in animation proficiency in the team).</p>
      </div>
    </div>

    <!-- Innovation -->
    <div id="P2" class="modal">
      <div class="modal-content">
        <span class="close" onclick="closeModal('P2')">&times;</span>
        <h1>Digital Innovation - Dyson discovery team</h1>
        <h3>Caveat</h3>
        <p>Due to the nature of the innovation work - designs, prototypes, research and product specific details are not able to be covered.</p>
        <h3>Objective</h3>
        <p>To identify emerging business and technological opportunities in the audio space to ensure the future range plan is both competitive and cutting edge.</p>
        <h2 class="step1">Step 1: Gather requirements</h2>
        <p><b>Goal:</b> To ensure any features and products designed fulfil both the users needs and the business needs.</p>
        <p><b>Process:</b> This began with stakeholder alignment with the business unit leads and the product managers to negotiate a set of requirements and form a working relationship. The other key stakeholders were with the engineering team to help understand the technical constraints and any functional requirements of the app in order to effectively support the product.
        </p>
        <p>At the same time, I launched into user research. For existing features we were able to interview and survey with a wide selection of external participants using UserTesting & UserZoom to better identify pain points in usage of competitor product features. For secret features we leveraged internal employees who best fit the target demographic and personas.</p>
        <p><b>Outcome:</b> By building a set of requirements, we were able to start creating user stories and business stories that covered the requirements and get them signed off with our product manager and the global business unit.</p>
        <h2 class="step2">Step 2: Design & Prototype</h2>
        <p><b>Planning: </b>At this stage we were able to start to build a feature set with the Product management team that fulfilled the requirements we had defined. The product management team then prioritised the feature set by comparing features with competitor products, cost to deliver and benefit.</p>
        <p><b>Outcome: </b> At this point I was able to begin the low fidelity and conceptual design phase, which I am unfortunately unable to show due to the secrecy around the innovation team.</p>
        <h2 class="step3">Step 3: Validation</h2>
        <p><b>Research: </b>When I proposed the initial designs, I looked to validate them using usability trials and interviews. These were enabled by the prototypes created in Figma or with the help of software engineers in our team to create a proof of concept for testing.</p>
        <p><b>Process: </b>By having participants tap through a prototype, we were able to identify key areas of improvement, of these areas we were able to adjust and retest them until they were fully validated and we had insights to inform our designs.</p>
        <p>The key insights included:</p>
        <ul>
          <li><b>Time is critical</b> - Users did not want to spend more than 5 minutes during product set-up.</li>
          <li><b>Motivation</b> - Users would be willing to spend time setting up app features initially if it enhanced their product experience, or helped reduce time manually fine tuning or fixing problems.</li>
        </ul>
        <p>The prototype also provided a good discussion piece to share with development teams to de-risk the proposal.</p>
        <p><b>Outcome: </b>A comprehensive review of the feature designs with interactive prototypes or technical proof of concepts with senior stakeholders in the Dyson Leadership Group. This is an opportunity to gather final feedback to make any necessary refinements or actions for the delivery team.</p>
        <h2 class="step4">Step 4: Review and Delivery</h2>
        <p><b>Challenge: </b>In this review one of the key features that was proposed was criticised for not being enough of a differentiator, and needing to be more unique in how the data and feature was visually presented.</p>
        <p>This raised several challenges including:</p>
        <ul>
          <li><b>Interpretability: </b>The visualisation would require tweaking and additional information in order to be both glanceably interpretable due to its abstract form, which contrasted the usual data graphs.</li>
          <li><b>Implementation: </b>The visualisation would have several implementation challenges, due to the desired format of the visualisation being shared being more 3 dimensional than anything that would be achievable with any standard platform or design system components.</li>
        </ul>
        <p><b>Solution: </b>There were a few directions the desired concept could be achieved. Either with a 3D model that would be rendered in-app, or creating the visual programmatically with code. I used my experience with Procedural graphics generation and 3D modelling to explore both options, and after reviewing both decided to use the procedural generated 3D graphics using shaders and GLSL code. From collaborating with the App team, we realised we were able to render this on both mobile platforms with the use of Metal and GL.</p>
        <p><b>Outcome: </b>A dynamically rendered shader could display the data within the app for the future feature. By creating it as a shader it could operate as a module that the delivery team could adopt easily without too much refactoring and rewriting, which in turn removes a lot of the risk associated with the feature. Onboarding prompts are used to teach users about the feature.</p>
      </div>
    </div>

    <!-- Ontrac -->
    <div id="P3" class="modal">
      <div class="modal-content">
        <span class="close" onclick="closeModal('P3')">&times;</span>
        <h1>Dyson OnTrac - MyDyson app</h1>
        <h3>Objective</h3>
        <p>Propose and deliver the app experience for the second generation dyson headphones within the accelerated launch timeline while rolling out the connected product design system MyDyson experience.</p>
        <h2 class="step1">Step 1: Research and requirements</h2>
        <p><b>Research:</b> Data gathering with the data science team on the Dyson Zone launch to understand areas of attrition and identify usability issues and successes.</p>
        <p>Key areas include: </p>
        <ul>
          <li>Users did not interact with location based air quality data.</li>
          <li>Users were confused with noise cancellation iconography and relied on the drilldown menu.</li>
          <li>Users struggled with the connection journey, particularly on iOS where there are two types of bluetooth connection that need to be established for full connected functionality. (BLE and BT classic)</li>
          <li>There were more speculative issues, by looking at online reviews. But these were uncertain due to the small sample size and the fact that some areas including product settings did not have tracking built in.</li>
        </ul>
        <p><b>Requirements:</b> To provide an app experience that enables the launch of the Dyson OnTrac product it needs to fulfil:</p>
        <p>User needs: </p>
        <ul>
          <li>Be able to control headphone noise cancellation & equaliser functions.</li>
          <li>Be able to manage key settings such as head detection.</li>
          <li>Be able to see product status and troubleshoot any faults or issues.</li>
          <li>Be able to onboard key product features.</li>
        </ul>
        <p>Business needs: </p>
        <ul>
          <li>Encourage users to install MyDyson app, and prompt continued use after set-up.</li>
          <li>Encourage sales of spares and accessories, and other Dyson products where possible.</li>
          <li>Help establish Dyson’s position in the headphone market segment.</li>
          <li>MVP app delivered by Q3 2024, to fit with the connected range plan.</li>
          <li>Align the app experience with the rest of the MyDyson app range.</li>
        </ul>
        <h2 class="step2">Step 2: Delivery plan</h2>
        <p><b>Proposition: </b>To reduce the risk of delaying the app launch and align to the tight roadmap, I mocked up a hybrid app interface that reuses elements from the Dyson Zone app experience due to sharing many of the same features as the Dyson Zone.</p>
        <img src="images/dyson_ontrac/newscreens.png" alt="The new design system screens">
        <p>As seen above, only the core screens would adopt the new design system including the onboarding/set-up screens, shop page, support and landing pages. Core screens were identified by reviewing the data tracking to discover what screens were most visited. The secondary screens like Noise Cancelling, Equaliser, sound data and settings screens reused the legacy components from the Dyson Zone app. This allowed them to be easily updated in isolation post launch while keeping the rest of the experience consistent with the rest of the Dyson range in the design system.</p>
        <p><b>Estimation:</b> I then brought this proposal to the app team managers and leads to get an estimate on the proposal, and get an idea of its feasibility to slot into the delivery roadmap. The developers that I worked with on the original Dyson Zone app originally were able to give a loose sizing to the proposition. However, due to priorities, the team that would be picking this up would be a newly raised team, which would likely stretch the time estimations.</p>
        <p><b>Review:</b> To manage stakeholder expectations, this proposition and the launch featureset had to be presented to the senior leadership team including Jake Dyson. After I had got the proposition signed off it was able to be planned into the app roadmap.</p>
        <h2 class="step3">Step 3: Development & Design System</h2>
        <p><b>Agile:</b> To kickstart development, I joined the new development team in Poland to form a multi-disciplinary scrum team and onboard them onto the proposed experience and the current MyDyson experience.</p>
        <p>By working agile, it enabled the team to identify edge cases, faults and issues quickly, and then be able to generate new design solutions for development quickly that could adopt existing screens and logic. </p>
        <img src="images/dyson_ontrac/oldscreens.png" alt="The old design system screens">
        <p>Key issues included:</p>
        <ul>
          <li>Aligning legacy component colours and styling to new design system guidelines.</li>
          <li>Rectifying data tracking in reused components.</li>
          <li>Covering edge-cases and  product specific faults that were not present before.</li>
          <li>Adapting Dyson Zone screens that were reused for use with Dyson OnTrac.</li>
        </ul>
        <p><b>Alignment:</b> To keep the Dyson Ontrac as in-line as possible with the rest of the MyDyson platform, it was necessary to use Design system components wherever possible, and propose new components to the design system team where existing ones did not fit the requirements.</p>
        <p>The main experiences that could be adopted and reworked included customer support pages, account pages and the e-commerce page. These required new content to be aligned to the existing flow, but allowed the team to minimise the risk and delivery time.</p>
        <p><b>New component patterns: </b>It was necessary to define new patterns and specifications for components more relevant to connected products. As a result of this, it was necessary to design and propose a scalable solution that could be reused across other products such as the purifiers.</p>
        <p>This included:</p>
        <ul>
          <li>Segmented button controls</li>
          <li>Alerts for fault states</li>
          <li>Connection and Product status</li>
          <li>Generic troubleshooting journeys</li>
        </ul>
        <img src="images/dyson_ontrac/troubleshooting.png" alt="An example of a troubleshooting journey">
        <p><b>Scalability:</b> To ensure the solutions were scalable and could be adopted by other products, we launched a series of workshops with the design team to gather all the existing legacy systems and identify where a component pattern could fulfil all the scenarios and what scenarios would require bespoke solutions.</p>
        <h2 class="step4">Step 4: Trial & Launch</h2>
        <p><b>Test: </b>Using the development prototype, we were able to trial and test the interface with a pool of internal Dyson employees. Steps were made to ensure participants were bluetooth headphone users and were not part of product launch so could experience the app without any preconceptions. Also, ensuring that none of the participants were UX practitioners so that we could keep feedback more authentic and less opinionated.</p>
        <p>Key findings included: </p>
        <ul>
          <li>15 usability errors, with 3 critical errors. These included areas of readability, and graph interpretability.</li>
          <li>Participants were impressed with the amount of information available in the headphones app.</li>
          <li>Participants did not expect product-related settings under the global app cog menu.</li>
          <li>Copy for the alerts was misleading.</li>
          <li>The middle tabs were not obviously scrollable, leading to some tabs being missed.</li>
          <li>Participants expected media controls on the app page.</li>
          <li>Participants found the recalibration process frustrating and confusing.</li>
          <li>The noise cancelling options provided were not entirely clear and differentiated.</li>
          <li>Participants felt that the Dyson OnTrac interface was a significant improvement over the current Dyson Zone app experience.</li>
        </ul>
        <p><b>Delivery:</b> There was a short opportunity of improving the experience before launch, and we prioritised the most critical feedback from the trial in driving these improvements that also had low development impact such as styling and copy for key features like the graphs. This was done by working agile in a multi-disciplinary scrum team where we could collaborate and quickly understand what was achievable in the final few sprints, while adding to the backlog for post launch improvements.</p>
        <img src="images/dyson_ontrac/MKBHDapp.png" alt="Picture of MKBHD using the Dyson OnTrac app">
        <p><b>Outcome:</b> The app experience was successfully launched alongside the product launch, and received glowing reviews online. On average ~12% of reviews mentioned the connected experience positively, as opposed to the ~2% that the Dyson Zone had.</p>
        <p>Reviews on the app experience include:</p>
        <ul>
          <li>"Elsewhere they are up to snuff ... I like that you can monitor both in-ear sound and external sound in the MyDyson app" <a href="https://www.expertreviews.com/uk/technology/audio/headphones/dyson-ontrac-review">-Expertreviews.com 2024</a></li>
          <li>"What's really neat is it includes sound exposure ... this is a really nifty little feature, very Dyson" <a href="https://www.independent.co.uk/extras/indybest/gadgets-tech/headphones-earphones/dyson-ontrac-headphones-review-b2588651.html">-Independent 2024</a></li>
          <li>"The Dyson app is pretty solid - it still does that real time thing ... it's still cool to look at once in a while" <a href="https://www.youtube.com/watch?v=iGYpj2gFu9Q">-MKBHD 2024</a></li>
          <li>"The app is pretty good too ..." <a href="https://www.stuff.tv/review/dyson-ontrac-review/">-Stuff.tv 2024</a></li>
        </ul>
      </div>
    </div>

    <!-- Zone -->
    <div id="P4" class="modal">
      <div class="modal-content">
        <span class="close" onclick="closeModal('P4')">&times;</span>
        <h1>Dyson Zone - Dyson Link app</h1>
        <h3>Objective</h3>
        <p>Delivering the connected experience for the first Dyson headphones, and iterating upon it with post launch improvements.</p>
        <h2 class="step1">Step 1: Design</h2>
        <p><b>Deep dive: </b>As a result of the product development framework, the product has been in development for some time now and the key concept and vision of the experience has already been explored, reviewed and signed off with Senior Stakeholders.</p>
        <p>In order to fully understand the proposed experience I was to refine and deliver I set out to define the current information architecture and where the key user journeys were.</p>
        <img src="images/dyson_zone/informationarchitecture.png" alt="Information architecture of the Dyson Zone app">
        <p>This highlighted areas that needed further design work, including much of the set-up journey and the help screens. By collaborating with the development team it was possible to identify each of the steps necessary for a successful connection and some of the anticipated failure paths such as when the product is not discovered, or if the connection fails.</p>
        <h2 class="step2">Step 2: Trial & Audit</h2>
        <p><b>Prototype: </b>To effectively trial the experience and gain insights on the experience, it was necessary to prototype the user interface. This would allow participants to tap through the screens while setting up the headphones for a more authentic and realistic product set-up journey and exploration of the key features.</p>
        <p>The goals of the trials were:</p>
        <ul>
          <li>Validating the user experience of the controls.</li>
          <li>Verifying the user interpretability of the graphs.</li>
          <li>Discovering if users are able to fully connect and set-up the product with the in-app set-up journey.</li>
          <li>Identifying potential faults and issues with the current experience.</li>
        </ul>
        <p><b>Internal trial: </b>I began with running an internal trial within the office with the use of a pre-production Dyson Zone and the prototype. There were 6 participants given the task of successfully setting up the headphones, who all had experience of using headphones but who had not had any personal experience with the Dyson Zone.</p>
        <p>Key findings:</p>
        <ul>
          <li>During set-up there was confusion with the two part bluetooth connection required for BLE and BT classic.</li>
          <li>During set-up there was difficulty setting up the visor correctly, due to putting headphones not backwards, and difficulty with the magnetic connection</li>
        </ul>
        <p>Based on these key findings, it became clear that additional information would need to be provided for the user to effectively set-up the product by the time they arrive on the homescreen so that the core functionality of the product was demonstrated. The core functionality being sound quality which would be demonstrated by a bluetooth connection where the user could play their own music, noise cancelling which would be enabled by the sound exposure graph, and finally purification which would be demonstrated by the controls alongside the air quality graph.</p>
        <p><b>Iterate: </b>In order to solve key onboarding issues, I set out to learn how to implement app animations for Dyson Link, which did not have any major animations at the time. I arrived at the solution of using Lottie animations by discussing with the app developers, and looked to animate the current vector illustrations in After Effects with simple movements to emphasise each step. </p>
        <p>To keep the animations focused and efficient, I aimed to have them loopable and no more than a few seconds long. Once I got the initial steps in place, I reviewed with the rest of the design team and then looked to enhance the animations with the graph editor to better create a more believable sense of weight and motion.</p>
        <p><b>London Trial: </b> While implementing some of the key changes, the insights team started to trial externally with potential users. To ensure the trial used the most up to date app experience, the development team worked to get the researchers pre-production apps and connected prototypes. The only issue was that the onboarding which contained the newest animation had not been implemented and built yet, so I quickly updated my prototype and got it onto the same demo phone so that the set-up experience could be re-trialled alongside the rest of the product experience with help of the prompts from the researchers.</p>
        <ul>
          <li>Purification had mixed perceived efficacy</li>
          <li>Positioning and design of the visor was a cause of frustration for many</li>
          <li>App is practical and provides relevant feedback on controls and environment</li>
        </ul>
        <h2 class="step3">Step 3: Iterations & Assets</h2>
        <p><b>Alignment:</b> Content in the app needed aligning with the rest of the campaign, so I collaborated with commercial copywriters, packaging design, user guides and the web team to ensure we all shared the most up to date copy and imagery in each platform.</p>
        <p><b>Audit: </b>When these final assets and animation files had been delivered, I conducted an end-to-end audit of the app with the test engineers in the team to ensure there was parity with the designed experience and the final implementation.</p>
        <img src="images/dyson_zone/app_MKBHD.png" alt="Picture of MKBHD using the Dyson Zone app">
        <p><b>Outcomes: </b>The Dyson Zone app launch was successful, launching on time alongside the new product and garnering overall positive feedback compared to the controversial product itself.</p>
        <p>Reviews on the app experience include:</p>
        <ul>
          <li>Described as having a "Good App" <a href="https://www.headphonesty.com/2023/05/review-dyson-zone/">-Headphonesty 2023</a></li>
          <li>Setup through the Dyson app is “simple” with “no issues synching with iPhone” and clear on-screen instructions. This ease of use is beneficial, especially given the headphones' complex features <a href="https://www.wired.com/review/review-dyson-zone/">-WIRED 2023</a></li>
          <li>"I've never seen anything like this with headphones apps and live realtime data" <a href="https://www.youtube.com/watch?v=tFdnCzfJPJ0">-MKBHD 2023</a></li>
        </ul>
        <p><b>Next steps: </b>Working on a backlog of post launch features to add to the app, and responding to any issues and feedback on the current experience.</p>
        <h2 class="step4">Step 4: Post launch design sprint</h2>
        <p><b>Problem: </b>People do not trust the Dyson Zone to protect them. This is exasperated by the current events of the New York Wildfires and the recent viral critical reviews for the product.</p>
        <p>This prompted a quick collaborative design sprint to get the project moving. This began with consulting key stakeholders to gather requirements</p>
        <p>User needs: </p>
        <ul>
          <li>I want to see what my product is currently protecting me from. So I can be more knowledgeable about the air I breathe in.</li>
          <li>I want to see what the product has protected me from this session/today/week. So I can make decisions to reduce my risk of health problems.</li>
          <li>I want to review the AQ data collected by my headset; because it is my data from my headset.</li>
        </ul>
        <p>Business needs: </p>
        <ul>
          <li>Tight time frames and to be able to deliver in time for the next development plan.</li>
          <li>Promote the purification functionality of the Dyson Zone.</li>
          <li>To increase usability of the AQ data pages.</li>
        </ul>
        <p>Technical considerations: </p>
        <ul>
          <li>Integrating Breezometer and sensor data may muddy the interface and AQ scales.</li>
          <li>Small changes favourable due to limited development resources.</li>
          <li>Breezometer API contract is uncertain, and also has some limitations with how data can be called and represented.</li>
        </ul>
        <p><b>Workshop:</b> I gathered several designers along with a few stakeholders involved in the product launch to explore some potential solutions for the problem statement and the current interface.</p>
        <p>Solutions explored included: </p>
        <ul>
          <li>Additional Onboarding screens about benefits of purification and AQ sensors</li>
          <li>Reworking the Breezometer page</li>
          <li>Overhauling the landing page</li>
          <li>Combining NO2 sensor data and AQ data into a single overall score.</li>
          <li>Reworking data help screens</li>
          <li>Replacing the graphs with more visually interesting representations of air quality data</li>
        </ul>
        <p>These key solutions were then reviewed with lead developers from both Android and iOS platforms to estimate complexity and feasibility. This was then measured against the perceived user and business benefit of each solution.</p>
        <p><b>Review: </b>To align on a single solution, I presented each of the design proposals alongside some estimations, risks and opportunities of each of them to the senior stakeholders for the APP team and the Dyson Zone product. As a result of the review, we were able to align on the solution of reworking and expanding the Breezometer section on the landing page in order to raise awareness of the overall air quality in your area. This also included a revision to the copy to be more transparent for each pollutant that was being measured, due to the confusion of users seeing sensor data and assuming it was a holistic view of their air quality, and not just based on NO2.</p>
        <p><b>Estimation: </b>This solution was sized as taking half a sprint for 2 teams (Android & iOS), and would require some testing on smaller devices due to increasing the size of the Breezometer section and reducing the size of the NO2 graph which also was the container for any in-line fault pop ups.</p>
        <p><b>Delivery: </b>I collaborated with the development teams during this sprint to ensure we could quickly roll out the changes and test usability for all devices we supported due to the updated copy and size specifications.</p>

      </div>
    </div>

    <!-- BigSleepCo -->
    <div id="P5" class="modal">
      <div class="modal-content">
        <span class="close" onclick="closeModal('P5')">&times;</span>
        <h1>The Big Sleep Company</h1>
        <h3>Objective</h3>
        <p>To assess and improve The Big Sleep Company’s online presence and baby sleep consultancy platform in order to support their move from a physical manual business to be more online and autonomous.</p>
        <h2 class="step1">Step 1: Discovery</h2>
        <p><b>Background:</b> To assess the current situation properly, I interviewed the co-owners at The Big Sleep Co. to understand how they felt about their platform and brand. I also got access to existing brand guidelines and source code for their website.</p>
        <p>This allowed me to capture the Mission and Vision statements to grasp their core purpose and ensure any solutions aligned with their long-term goals.</p>
        <h2 class="step2">Step 2: Audit and research</h2>
        <p><b>Audit: </b>To identify any key usability issues or areas of attrition for the current platform solution, and build a SWOT analysis.</p>
        <img src="images/big_sleep_co/onboarding_audit.png" alt="Visualisation of the onboarding process">
        <p>Strengths:</p>
        <ul>
          <li>Customers find a friendly down-to-earth consultant easier to trust with their children than someone overly clinical.</li>
          <li>Locally based business appeals to customers.</li>
          <li>Social media community of parents.</li>
          <li>Word of mouth reviews received well.</li>
        </ul>
        <p>Weaknesses:</p>
        <ul>
          <li>Dependence on in-person consultations holds back business scalability.</li>
          <li>Social media requires upfront time investment for inconsistent results.</li>
          <li>Users are visiting the website without committing to a payment plan.</li>
        </ul>
        <p>Opportunities:</p>
        <ul>
          <li>Tiered pricing options to suit different budgets.</li>
          <li>Variety of support options available.</li>
        </ul>
        <p>Threats:</p>
        <ul>
          <li>Competitors in the general UK area are becoming more well known.</li>
          <li>With the cost of living crisis, pricing is much more competitive.</li>
        </ul>
        <p><b>Target audience: </b>Leveraging insights from their key social media platforms on Facebook and Instagram to better understand demographics, goals and behaviour.</p>
        <p>This was also an opportunity to find out what the customer perception was for the Big Sleep Co. and how they engage with them at different touchpoints on the platform.</p>
        <p><b>Personas: </b>From this I was able to draw up key persona’s based on their current user base and present them to the stakeholders to ensure they aligned to their understanding of their users, and also if it aligned with their target demographic.</p>
        <img src="images/big_sleep_co/user_flow.png" alt="Visualisation of users flow to purchase">
        <p><b>Competitor analysis: </b>By comparing the Big Sleep Co. to similar businesses and seeing what their successes were we can see how the platform can become more competitive in the baby sleep consultation space, especially in the local area where in-person visits are possible.</p>
        <p>Key competitors included:</p>
        <ul>
          <li>Little Dreams Consulting - Local</li>
          <li>Chill Baby Sleep</li>
          <li>No Milk Like Mamas</li>
          <li>Little Ones</li>
        </ul>
        <h2 class="step3">Step 3: Exploration</h2>
        <p><b>Website redesign: </b>Making a list of changes to the current website to promote sales and engagement.</p>
        <ul>
          <li>Visual Hierarchy revised</li>
          <li>Readability of certain elements. Multiple sections fail WCAG contrast accessibility checks.</li>
          <li>Streamlining test and clickable content so the website is more glanceable, particularly on mobile.</li>
        </ul>
        <img src="images/big_sleep_co/readability.png" alt="Suggested readability improvments">
        <p><b>App concepts: </b>Exploring the direction of a mobile only platform, this would be the platform for paid content, you can see the proposed structure.</p>
        <p>You can find the prototype <a href="https://www.figma.com/proto/ZUMpzzfRtvhICxSfKU6LeA/TheBigSleepCo?node-id=20-96&scaling=scale-down&page-id=0%3A1&starting-point-node-id=20%3A96 ">here.</a></p>
        <p><b>Social media: </b>Exploring how to drive social media engagement, options include:</p>
        <ul>
          <li>Targeted ads using Facebook lookalike</li>
          <li>Make use of widgets on website for social media accounts</li>
          <li>Mass following competitors</li>
          <li>Look into short free guides to help hook readers and drive the vision of the company being experts in the field</li>
          <li>Podcasts and live conferences</li>
          <li>Make use of referral codes and bonuses to lean on already effective direct word-of-mouth advertising</li>
        </ul>
        <h2 class="step4">Step 4: Recommendations</h2>
        <p><b>Presentation: </b>I presented a series of recommendations to improve their current platform, along with opportunities for scaling up the business. You can find the deck <a href="https://drive.google.com/file/d/12FMnseBHJIwJaLKWxhKGr_fp9afN_-uw/view">here.</a></p>
        <img src="images/big_sleep_co/prototype.png" alt="Screens from the mobile prototype">
        <p><b>Scaling up: </b>Growing a new target audience targetting a younger generation that is more present on online and mobile platforms. This could include expanding social media presence, building a bespoke app, multiple care packages for different budgets and levels of support.</p>
        <p>Platform improvements:</p>
        <ul>
          <li>SEO and discoverability. (use of backlinks and social media widgets)</li>
          <li>Streamline text and clickable assets</li>
          <li>Value Proposition, emphasise the need for course content to enable/streamline in-person paid consultations</li>
          <li>Statements and Case studies from previous customers</li>
        </ul>
        <p>Streamlining overall user investment flow: </p>
        <ul>
          <li><b>1. Content: </b>Gain user's interest from free content - Blog/Q&A</li>
          <li><b>2. Lead magnet: </b>Gain user's contact - Mailing list.</li>
          <li><b>3. Qualifier: </b>Gain user's time - Social media engagement.</li>
          <li><b>4. Product: </b>Gain user's financial investment - Course purchase.</li>
        </ul>
      </div>
    </div>

    <!-- Burning reef -->
    <div id="P6" class="modal">
      <div class="modal-content">
        <span class="close" onclick="closeModal('P6')">&times;</span>
        <h1>The Burning Reef - Digital Media BSc project</h1>
        <p>Department of Computer Science and Creative Technology</p>
        <h3>Background</h3>
        <p>The initial drive for this project began with an interest to learn 3D web technology. The topic for the project was discovered following an interest in the recent Extinction Rebellion protests. The project is a fantastic fit for my portfolio as it covers a large portion of my preferred skills, particularly including the user experience material and additional media created during the development such as the demo video.</p>
        <h3>Objective</h3>
        <p>The aim of the project is to discover if by eliciting an emotional response, users are more willing to change their lifestyle or opinion of ocean degradation.</p>
        <h2 class="step1">Step 1: Scope</h2>
        <p><b>Concept: </b>The Burning Reef builds an immersive narrative around the effects of this ongoing degradation through a colourful and bustling coral reef that will gradually degrade until it becomes lifeless and grey. The audio will match these visual changes, starting as an exciting soundtrack that will gradually reduce in tempo and exaggerate feelings of dread and tension in the user while the time left to explore the ocean runs out. By having the changes in ambience tied to the degrading coral reef, the experience can present the effects of careless and wasteful habits to the user and creating awareness of how they can change their habits.</p>
        <img src="images/burning_reef/moodboard.png" alt="Mock up of reef in 3D software">
        <p>You can watch an overview video of the project <a href="https://youtu.be/JIOuXj2So3w">here.</a></p>
        <p>Deliverables</p>
        <ul>
          <li>Interactive narrative driven 3D experience</li>
          <li>Immersive and minimal user interface built into an adaptive webpage</li>
          <li>Ambient and adaptive audio integrated with the narrative that elicits an emotional response</li>
        </ul>
        <p><b>Report: </b>For a detailed summary on my process and outcomes, find my write up <a href="https://drive.google.com/file/d/1m-I61_6AdRpabKG07wqvPNwEGbC8yUC_/view?usp=sharing">here.</a></p>
        <h2 class="step2">Step 2: Research</h2>
        <p><b>Research Goal: </b>The project seeks to explore the direct effects a changing ambience can have on the user during an experience and establish whether an emotional investment in the experience can lead to lasting changes of opinion even after the experience has ended. The effectiveness of the experience will be analysed through the observations that will take place during user testing.</p>
        <p><b>Environmental research: </b>By exploring the direct causes and effects of ocean degradation, the experience will be able to effectively inform users and spread awareness. For example, the most heavily affected types of environments are continental shelves, rocky reefs, coral reefs, seagrass beds, and seamounts. By having the audio-visual illustrate these areas particularly prone to ocean degradation changing overtime a narrative will begin to form during use.</p>
        <p><b>Ethical concerns: </b>Alongside standard research practices like infosheets, privacy notices and consent forms; the main ethical concern of the project is that it intends to elicit an emotional response that might influence users’ habits. When providing awareness on ocean degradation to the users, it must be ensured that while information provided is objective, the experience itself is subjective to the user.</p>
        <p><b>Thematic analysis: </b>Following the interviews with the five participants, thematic analysis was used through an affinity diagram to draw out common themes between participants from each question answered. It was then possible to measure the participants interest in ocean degradation and discover that while all users agreed it was a pressing matter, only three were willing to strongly agree to the statement.</p>
        <img src="images/burning_reef/user_journey.png" alt="User Journey of the experience">
        <p>By forming a picture of the user group early, it was possible to build empathy maps and plan their user journey throughout the experience. The user journey maps would then build upon the lo-fi prototype, the storyboard of the narrative. As is standard with an incremental agile development style, this first prototype will inform any technical decisions and research for the project. According to interview participants, most would likely struggle to spend more than 10 minutes on an interactive experience, so it must be ensured the standard experience use time that has been storyboarded falls within that time frame.</p>
        <h2 class="step3">Step 3: Practice</h2>
        <p><b>Gamification: </b>By implementing gamification techniques users are encouraged to seek out the artifacts themselves, with the information being treated as a reward rather than being forced onto users where it might be viewed as a burden. An example of how awareness is typically spread is through infographics which often demand action. The motivation is considered extrinsic when built from social guilt and when applied through gamification can be considered “Black Hat Gamification”, this type of motivation tends to be short lived compared intrinsic motivations that are built without obvious external cause. As the experience focuses on eliciting an emotional response it is possible to lead these extrinsic motivations into intrinsic ones.</p>
        <p><b>3D environment: </b>In the initial prototype for the video demo a smaller scale premade reef was modelled in Autodesk Maya to demonstrate the concept and bring to light exactly the sort of scale the reef would need to be to allow the user to freely explore without feeling too confined. It became evident the reef would have to be at least several times bigger, and that programaticprocedural generation might be necessary.</p>
        <img src="images/burning_reef/maya_mockup.png" alt="Mock up of reef in 3D software">
        <p><b>Procedural generation:</b> For more context of how the landscape was generated from a technical point of view, read the full documentation or check out my GitHub page for the project <a href="https://github.com/alexrehopkins/burning_reef">here. </a></p>
        <p><b>Degradation: </b>The core idea was that the user would explore the terrain looking for artefacts that would reward them with information on ocean degradation. If they took too long to collect the artefacts the reef would degrade and collapse. A sense of time was created through the dynamically changing visuals and audio, that would elicit a melancholic or panicked emotional response from the users.</p>
        <p>These effects were created first through CSS filters over the render window that would turn the screen greyscale over time, and the slowing of a custom ambient soundtrack. Though after implementing the instanced mesh method, it was much more accessible to update the visuals on all the individual coral to greater reflect the bleaching process that takes place when coral dies as they could turn to white by altering the material colours saturation and luminance instead of the original dark grey achieved through CSS filter.</p>
        <img src="images/burning_reef/wireframe.png" alt="Wireframe of UI">
        <p><b>User Interface: </b>The user interface was created and overlayed on top of the canvas using HTML elements, CSS was used for animations and iconography was imported in that I created from Adobe Illustrator.</p>
        <h2 class="step4">Step 4: Outcomes</h2>
        <p>The project was a success and marks the end of my BSc at the University of West of England. I was awarded a 1:1 for the project. You can try out the prototype yourself <a href="https://burningreef.netlify.app/">here.</a></p>
        <p><b>Outcome: </b>The Burning Reef project began as an exploration into how an audio-visual can elicit an emotional response. It stands as an example of how an emotional response can cause users to invest more time into the teaching experience, particularly when combined with gamification techniques. Using gamification, information that might otherwise go unread by many users can become engaging and even exciting by intrinsically motivating them to learn more.</p>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/JIOuXj2So3w"></iframe>
        <p>The core gamification mechanic is the artefact searching function, where upon making contact a unique object in the coral reef the experience plays a short animation that leads them to their artefacts page. For each artefact discovered information is presented to the user about the type of ocean degradation the artefact is associated with and the steps the user can take to prevent further that ocean degradation.</p>
        <p><b>User testing: </b>Outside of the emotional reactions observed during user testing, the quantifiable change seen in Likert scale results proves that users were influenced enough by the experience that those who originally only agreed to the statement were willing to change their opinion to strongly agree.</p>
        <p><b>Key usability issues: </b>There were a few minor usability issues observed from testing, which were reviewed and improved before publishing. These included the automatic randomly placed artefacts having a limit to how far they generate to help keep the duration of the overall experience within the expected timeframes. There was also a key correlation between users who took too long being from within an older demographic.</p>
        <p>This might have been due to an innate familiarity with the gamification techniques implemented in the experience such as using the compass to hunt down artefacts. It would imply interactive audio-visuals could be particularly successful at emotionally stimulating and informing a younger demographic such as students who are already familiar with technology that employs gamification techniques and control schemes. For the Burning Reef, this did result in some participants speeding through the experience and not getting the chance to see the ocean degrade as much as it might have, which might hinder the experiences potential for an emotional reaction.</p>
        <p><b>Next steps: </b>Given more time to develop the project, a more controlled tutorial section of the experience could be implemented to allow users who might struggle early on to be guided through the early stages of the experience and build their confidence exploring the 3D environment. Non-essential developments would include finetuning and building upon the visual and audio elements with volumetric lighting, particle effects and more adaptive audio to enhance the overall experience through heightened immersion</p>
        <p>A foreseeable long-term future for The Burning Reef would involve getting involved with an ocean related environmental campaign and implementing it as an educational interactive installation. If you'd like to explore other future's for this project with me, reach out to me at my <a href="https://www.linkedin.com/in/ahop/">LinkedIn.</a></p>
      </div>
    </div>

    <!-- Panacea -->
    <div id="P7" class="modal">
      <div class="modal-content">
        <span class="close" onclick="closeModal('P4')">&times;</span>
        <h1>Panacea - Prevail 2021</h1>
        <h3>Objective</h3>
        <h2 class="step1">Step 1: Concept</h2>
        <p><b>Vision:</b> To be at the forefront of the immersive performance scene, evolving how people engage with music and visuals. We envision a future where every DJ set is an unforgettable, fully immersive journey that transcends the traditional boundaries of sound, sight, and emotion.</p>
        <p><b>Mission:</b> To create transformative, multi-sensory experiences by blending cutting-edge audio and 3D visuals. Where soundscapes meet landscapes, we aim to tell a story that will leave the audience thoughtful and questioning things. The first experience is set in distant future Bristol to align with the location of the initial venues, but future experiences will be based on other locations.</p>
        <p>Values: </p>
        <ul>
          <li>Abstract</li>
          <li>Nuanced</li>
          <li>Dynamic</li>
          <li>Contemplative</li>
          <li>Dystopian / Solarpunk</li>
          <li>Rewilding</li>
        </ul>
        <p><b>Workshop:</b> I led a workshop to help the team form the visual direction of the project. The output of this session included a moodboard and colour palette.</p>
        <p><b>Concept video: </b>Using After Effects, I created the concept video for the first act of the experience, 'We Will Fall' following feedback from the workshop.</p>
        <p><b>Outcome: </b>With the concept video, moodboards and vision, we had something to share to stakeholders for feedback at Prevail and also set the foundation for the visual direction of the real implementation.</p>
        <h2 class="step2">Step 2: Design & Development</h2>
        <p><b>Storyboarding: </b>Next steps involved designing the overall experience, I did this iteratively with storyboards that I could then share and get feedback from the team with.</p>
        <p>The core story covers the emergence into the dystopian Bristol cityscape, that then begins to explode and fragment. Finally all the fragmented pieces lift into the sky, and when they land they land into a new rewilded world, that is flooded with life and greenery.</p>
        <img src="images/panacea/storyboard.png" alt="Storyboard of Panacea">
        <p><b>3D experience: </b>Collaborating with Jamie Bragg, developer of the team, we Unity to model and develop the 3D environment. In order to capture the feel of Bristol, we took 3D scans and pictures of areas in and around Bristol to import into the Unity project as 3D models and background elements. This kept the experience feeling cohesive in the more grounded acts of the experience that follow the initial portal segement of 'We Will Fall' that was based on the initial concept video.</p>
        <img src="images/panacea/3d_landscape.jpg" alt="Bristol lanscape in Panacea">
        <p>The 3D environment could be made into a guided movie by creating a camera that follows a trail similar to a rollercoaster. We were then able to animate elements by pulling in certain frequencies from the audio track Ran Barnea was producing, allowing elements like the buildings to dance to the music, and triggering events like lasers to be on beat with the music.</p>
        <p><b>Refining: </b>Finally to fine tune the experience, I added some simple post-processing effects to give the experience a more immersive movie-like feel. It also better allowed the experience to have a dynamic colour palette that aligned with change of mood that happens after the midway point.</p>
        <p>We were also able to collaborate with Tom Knott who helped mixed the music.</p>
        <h2 class="step3">Step 3: Website & Promotionals</h2>
        <p><b>Branding: </b>To be able to promote the experience we needed promotional materials and a visual identity. I began by designing the logo, colour palette and core imagery. I modelled the logo around the Rod of Asclepius based on it's medicinal and healing connections that relate it to the concept of Panacea and it's healing of the world.</p>
        <p><b>Poster: </b>By combining the logo, alongside imagery from the 3D experience I was able to create a poster for the event. You can see this below.</p>
        <p> I also created variations for either of the two launch events and also for different platforms such as Instagram which favour square images for their content, as opposed to the A3 size for our physical poster prints.</p>
        <img src="images/panacea/poster.png" alt="Poster for event">
        <p>To align with the digital standard of posters, I created an animated version of the poster for use on Instagram stories and on other social media platforms.</p>
        <p><b>Product design: </b>I also mocked up and designed some Vinyl and CD packaging for the physical products we could sell at the event.</p>
        <img src="images/panacea/vinyl_mock_up.png" alt="Vinyl mock up">
        <p><b>Outcome: </b>We launched the website a month in advance, and printed and put posters around Bristol City Centre.</p>
        <p>You can find the countdown website on the Internet Archive <a href="https://web.archive.org/web/20240325034528/https://panacea.city/">here.</a></p>
        <h2 class="step4">Step 4: Performance</h2>
        <p><b>Prevail 2021: </b>Our initial performance was at the <a href="https://bristolbeacon.org/">Bristol Beacon Centre</a> in Bristol. We had a massive turnout of over 60 people over the course of the performance, with multiple asking about the next events.</p>
        <p><b>Strange Brew: </b>The following performance was at <a href="https://www.strangebrewbristol.com/">The Strange Brew</a>, which sold over 50 tickets.</p>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/E3L3T_CWhEQ"></iframe>
        <p><b>Outcomes: </b>Overall the project was a success and we managed to perform the event multiple times at two different popular Bristol venues.</p>
        <p><b>Next steps: </b>The next steps will be designing a follow up experience based on the same formula but using a different location, some ideas we have discussed include London, Edinburgh or even somewhere abroad.</p>
      </div>
    </div>

    <!-- Critical Eye -->
    <div id="P8" class="modal">
      <div class="modal-content">
        <span class="close" onclick="closeModal('P8')">&times;</span>
        <h1>Critical Eye - IC Visual Lab</h1>
        <h3>Background</h3>
        <p>CRITICAL EYE: Visual Archives for Education is an innovative pedagogical initiative that uses photography archives to encourage critical thinking in young people in the school context.</p>
        <h3>Objective</h3>
        <p> The aim is to offer a scalable and user-friendly digital platform for students to develop a critical approach towards images through a series of practical activities and original resources developed in collaboration with artists, educational institutions and school teachers.</p>
        <h2 class="step1">Step 1: Planning for agile</h2>
        <p><b>Agile: </b>By working in a small team it was essential we took on an agile framework tailored for small enterprises. This allowed each team member to take on multidisciplinary roles in order to get the project off the ground. I worked both in front-end and as a designer in order to create proof of concepts and defining the standard for the initial and future education guides.</p>
        <h2 class="step2">Step 2: Research</h2>
        <p><b>User research: </b>Defining the user groups and target audience with the team, and then creating personas based around these.</p>
        <ul>
          <li>Student</li>
          <li>Teacher</li>
          <li>Third-party contributor</li>
          <li>External viewer</li>
        </ul>
        <p><b>Journey mapping: </b>Identifying key user journeys based on the user groups we have identifed.</p>
        <img src="images/critical_eye/user_journey.png" alt="User journey of a user in Critical Eye Project">
        <p><b>Competitors: </b>Research into existing image archival tools and existing tools used in education.</p>
        <p><b>Technology: </b>Exploration into potential technology platforms that would support webview and a back-end for easily writing to the image archive. </p>
        <img src="images/critical_eye/research.png" alt="Tech research from Critical Eye Project">
        <p>Key platforms included using Pawtucket and WordPress, where Pawtucket would enable more control over the platform but would require more upfront investment to create guides.</p>
        <p><b>Constraints: </b>Defining requirements by looking into ethics of an imagery archive used in education. Understanding the scope of how future guides could be created by external parties.</p>
        <h2 class="step3">Step 3: Prototype</h2>
        <p><b>Process: </b>Using Adobe XD to mock up a prototype of the first guide and core experience.</p>
        <p><b>Stakeholders: </b>We established a key working relationship with Bristol Photo Festival to understand what photography we could use, and how we could use their platform for exposing the project locally.</p>
        <p><b>First guide: </b>I sourced initial assets from creative commons content and project imagery to demonstrate the feature and effectiveness of the guides. By putting in assets into the prototype, and getting signed off with the rest of the team we were able to start the roll out of the first guide.</p>
        <p><b>Outcome: </b>Prototype shared and reviewed with the rest of the team to gather feedback and make changes before preparing for development.</p>
        <h2 class="step4">Step 4: Delivery</h2>
        <p><b>Iterative graphic design: </b>Working iteratively with frequent design reviews to build a set of graphics, iconography and brand guidelines for use in the web project and prototype.</p>
        <img src="images/critical_eye/icons.png" alt="iconography from Critical Eye Project">
        <p><b>Stylesheets: </b>Collaborating with the developer, I used the style guide I had created to form a CSS stylesheet for use in the web project.</p>
        <p><b>Audit: </b>I checked the first guide when it was developed against the initial prototype, creating a list of final tweaks before the first round of user testing.</p>
        <img src="images/critical_eye/audit.png" alt="Side by side comparison between prototype and implementation">
        <p><b>Outcome: </b>Rolling out the guide to the first session of real user testing in the classroom was a success. We gathered some critical feedback and I compiled a list of recommendations to make to the core experience and future guides which I’m unfortunately unable to share due to the nature of the project being rolled out officially in September.</p>
      </div>
    </div>

    <!-- SAM-APP -->
    <div id="P9" class="modal">
      <div class="modal-content">
        <span class="close" onclick="closeModal('P9')">&times;</span>
        <h1>SAM-APP for Anxiety - CodeWest</h1>
        <h3>Objective</h3>
        <p>To empower individuals in their mental health journey through engaging animated videos and interactive games that teach sustainable self-help practices and promote healthier habits.</p>
        <h2 class="step1">Step 1: Investigation</h2>
        <p><b>Literature review: </b>Looking into psychological research around mental health and anxiety, and the steps someone suffering could take to improve.</p>
        <p><b>Competitor analysis: </b>Exploring similar self-help apps and the topics they cover.</p>
        <p>Competitors:</p>
        <ul>
          <li>Calm</li>
          <li>What's Up? A Mental Health App</li>
          <li>Breathwrk</li>
          <li>Moodnotes</li>
          <li>MindShift CBT</li>
          <li>Breaking the cycle</li>
          <li>Colorfy</li>
        </ul>
        <p>Key themes and topics found in competitors: </p>
        <img src="images/sam_app/research.png" alt="Key themes of regulating anxiety">
        <p><b>Alignment: </b>Sharing the choice topics with stakeholders to get sign off on which concepts to explore more thoroughly for use in the app, and ensuring they align with the purpose of the app.</p>
        <h2 class="step2">Step 2: Interactive games</h2>
        <p><b>Concept: </b>Initially exploring what tools and interactive experiences the app could offer on its own. This was seen by our stakeholders as the ideal outcome for each topic as it would encourage repeated use of the app and careful guide and direct users through each practice.</p>
        <p>Contrary to this, some concepts were better approached as learning animations that the user could view to teach themselves the habits or to raise awareness on things. For example this included the sleep guidance topic.</p>
        <p><b>Technical implementation:</b> Creating interactive games and tools needed to be done with consideration of the mobile platform. By speaking with the development team the easiest solution seemed to be to create them with the HTML, CSS and JavaScript and then render them in a webview.</p>
        <p><b>Devlopment:</b> The concepts I explored as tools included a meditative drawing tool, where users could swipe on the screen to reveal landscape photos. This was done with JavaScript I had written, and used royalty free images to create the gallery users could choose from.</p>
        <img src="images/sam_app/code_projects.png" alt="Screenshots of code projects">
        <p>Another concept I developed was a journalling tool about letting go, where users could type in thoughts and feelings and then sail them down an animated river to prompt the meditative exercise of letting go. This was done with CSS animations and assets I created.</p>
        <h2 class="step3">Step 3: Animations</h2>
        <p><b>Storyboarding: </b>For concepts that were de-scoped as interactive games or tools, this was an opportunity to build out the concepts as animations. Each concept was sketched out with a few core story arcs over a few panels, ensuring it fulfilled the original purpose.</p>
        <p><b>Assets: </b>Once storyboards were refined and validated, the next step was to gather key assets and brand guidelines. These were recovered from the brand guidelines that were in-place for the app currently.</p>
        <p>Using Adobe Illustrator and the brand guidelines, I was able to create some key visual assets for use in the animations. This included some recurring characters that would appear in each animation.</p>
        <p><b>Animation process: </b>Importing the key assets into After Effects then allowed me to drop them onto the timeline and then begin keyframing by looking at the initial storyboards.</p>
        <img src="images/sam_app/sleep.png" alt="Sleep animation stages">
        <p>Once the initial animations were done we reviewed the concepts as a team, gathering feedback and recommendations.</p>
        <p><b>Refinement: </b>It was then time to fine tune the animations, adding visual effects such as cross-fades, and adding more weight and satisfaction to the animation with the graph editor.</p>
        <h2 class="step2">Step 4: Implementation</h2>
        <p><b>Delivery: </b>Finally when the finished product was completed, there was a final asset handoff, creating various file formats for either app platform and for use on the web.</p>
        <p>Finally before leaving the project, I stored the source files onto the project's GitHub repository to ensure they could be revisited, or edited if the situation arose and they needed refining. For example, if the brand guidelines evolved, or if they wanted to look into supporting more languages or device types.</p>
      </div>
    </div>

    <script>
      function openModal(modalId) {
        document.getElementById(modalId).style.display = "block";
        document.body.classList.add('modal-open');
      }
    
      function closeModal(modalId) {
        document.getElementById(modalId).style.display = "none";
        document.body.classList.remove('modal-open');
      }
    
      // Close the modal if the user clicks outside the modal content
      window.onclick = function(event) {
        const modals = document.getElementsByClassName('modal');
        for (let modal of modals) {
          if (event.target == modal) {
            modal.style.display = "none";
            document.body.classList.remove('modal-open');
          }
        }
      }
    </script>
    
    </body>
</html>